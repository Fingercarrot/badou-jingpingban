import torch
import torch.nn as nn
import numpy as np
from collections import Counter

import matplotlib.pyplot as plt

"""

基于pytorch框架编写模型训练
实现一个自行构造的找规律(机器学习)任务
规律：x是一个6维向量
    如果第1个数最大，属于第1类
    如果第2个数最大，属于第2类
    如果第3个数最大，属于第3类
    如果第4个数最大，属于第4类
    如果第5个数最大，属于第5类
    如果第6个数最大，属于第6类
"""

class TorchModel(nn.Module):
    def __init__(self, input_size):
        super().__init__()
        self.linear = nn.Linear(input_size, 6)
        self.activation = torch.softmax  #softmax
        self.loss = nn.functional.cross_entropy  #loss函数采用交叉熵损失

    # 当输入真实标签，返回loss值；无真实标签，返回预测值
    def forward(self, x, y=None):
        x = self.linear(x) # (batch_size, input_size) -> (batch_size, 1)
        y_pred = self.activation(x, 1)  # (batch_size, 1) -> (batch_size, 1)
        if y is not None:
            return self.loss(y_pred, y)
        else:
            return y_pred

def build_sample():
    x = np.random.random(6)
    index_of_max = np.argmax(x)
    if index_of_max == 0:
        return x, 0
    elif index_of_max == 1:
        return x, 1
    elif index_of_max == 2:
        return x, 2
    elif index_of_max == 3:
        return x, 3
    elif index_of_max == 4:
        return x, 4
    elif index_of_max == 5:
        return x, 5

def build_dataset(total_sample_num):
    X = []
    Y = []
    for i in range(total_sample_num):
        x, y = build_sample()
        X.append(x)
        Y.append(y)
    return torch.FloatTensor(X), torch.LongTensor(Y)

# 测试代码
# 用来测试每轮模型的准确率
def evaluate(model):
    model.eval()
    test_sample_num = 500
    x, y = build_dataset(test_sample_num)
    count_dict = Counter(y.tolist())
    # 输出结果
    print('本次预测集中共有:')
    for key, value in count_dict.items():
        print(f"{key} 类样本 {value} 个")
    correct, wrong = 0, 0
    with torch.no_grad(): # 不计算梯度
        y_pred = model(x) # 模型预测

        for y_p, y_t in zip(y_pred, y): #与真实标签进行对比
            index_of_max = np.argmax(y_p)
            if index_of_max == y_t:
                correct += 1
            else:
                wrong += 1
    print("正确预测个数：%d, 正确率：%f" % (correct, correct / (correct + wrong)))
    return correct / (correct + wrong)

def main():

    # 配置参数
    epoch_num = 500 #轮数
    batch_size = 10 #每次样本个数
    train_sample = 5000 # 每轮训练总共训练的样本总数
    input_size = 6 #输入向量维度
    learning_rate = 0.01 #学习率

    # 建立模型
    model = TorchModel(input_size)
    # 选择优化器
    optim = torch.optim.Adam(model.parameters(), lr=learning_rate)
    log = []
    # 创建训练集，正常任务是读取训练集
    train_x, train_y = build_dataset(train_sample)
    # 训练过程
    for epoch in range(epoch_num):
        model.train() # 模型进入训练状态
        watch_loss = [] # 打印loss变化
        for batch_index in range(train_sample // batch_size):
            x = train_x[batch_index * batch_size : (batch_index + 1) * batch_size]
            y = train_y[batch_index * batch_size : (batch_index + 1) * batch_size]
            loss = model(x, y) # 计算loss
            loss.backward() # 计算梯度
            optim.step() #更新权重
            optim.zero_grad() # 梯度归零
            watch_loss.append(loss.item())
        print("============\n第%d轮平均loss:%f" % (epoch + 1, np.mean(watch_loss)))
        acc = evaluate(model)
        log.append([acc, float(np.mean(watch_loss))])
    # 保存模型
    torch.save(model.state_dict(), "model_my.pt")
    # 画图
    print(log)
    plt.plot(range(len(log)), [l[0] for l in log], label="acc") # 画acc曲线
    plt.plot(range(len(log)), [l[1] for l in log], label="loss") # 画loss曲线
    plt.legend()
    plt.show()
    return

# 使用训练好的模型做预测
def predict(model_path, input_vec):
    input_size = 6
    model = TorchModel(input_size)
    model.load_state_dict(torch.load(model_path))
    print(model.state_dict())

    model.eval() #测试模式
    with torch.no_grad(): #不计算梯度
        result = model.forward(torch.FloatTensor(input_vec))
    for vec, res in zip(input_vec, result):
        index_of_max = np.argmax(res)
        print("输入：%s, 预测类别：%d, 概率值：%f" % (vec, index_of_max, res[index_of_max]))  # 打印结果

if __name__ == "__main__":
    main()
    # x, _  = build_dataset(100)
    # print(x.tolist())
    # test_vec = [[0.902249276638031, 0.2382115125656128, 0.12273965775966644, 0.4029921889305115, 0.4893737733364105, 0.6984485983848572], [0.06517008692026138, 0.9432169795036316, 0.37645870447158813, 0.9555317163467407, 0.9262617826461792, 0.5756285190582275], [0.82233065366745, 0.24106188118457794, 0.27236509323120117, 0.021819865331053734, 0.2805770933628082, 0.04693847522139549], [0.977790117263794, 0.7620230913162231, 0.16102516651153564, 0.7047338485717773, 0.10505394637584686, 0.26312240958213806], [0.967677891254425, 0.47260409593582153, 0.42675310373306274, 0.25650081038475037, 0.22436091303825378, 0.004668458830565214], [0.3217427432537079, 0.9374688863754272, 0.6174554228782654, 0.7210273742675781, 0.629194438457489, 0.9646129012107849], [0.9850696325302124, 0.9327629208564758, 0.23485730588436127, 0.3291942775249481, 0.7371196746826172, 0.5759886503219604], [0.6639650464057922, 0.6324778199195862, 0.19005581736564636, 0.726833701133728, 0.2562579810619354, 0.5194799304008484], [0.8904818892478943, 0.11335045844316483, 0.7977980375289917, 0.30115199089050293, 0.9413806200027466, 0.6164892315864563], [0.9187235236167908, 0.2412349432706833, 0.8051078915596008, 0.8616608381271362, 0.16129258275032043, 0.19327020645141602], [0.23381806910037994, 0.8771972060203552, 0.578504741191864, 0.5860082507133484, 0.7565212249755859, 0.7114210724830627], [0.8687686324119568, 0.3583870828151703, 0.8297185897827148, 0.4477260410785675, 0.9523807168006897, 0.0591832660138607], [0.5289157032966614, 0.18229708075523376, 0.6864408254623413, 0.7079756259918213, 0.15229690074920654, 0.8813759088516235], [0.16904045641422272, 0.27741390466690063, 0.5278406143188477, 0.9776529669761658, 0.1912410706281662, 0.11424289643764496], [0.816384494304657, 0.8058459162712097, 0.3009946942329407, 0.1705654114484787, 0.10593147575855255, 0.11953949928283691], [0.4076569080352783, 0.8220866322517395, 0.26569321751594543, 0.7732574939727783, 0.9937929511070251, 0.5883205533027649], [0.05208582431077957, 0.03635302186012268, 0.06252233684062958, 0.047172609716653824, 0.20215080678462982, 0.656529426574707], [0.016575217247009277, 0.20242972671985626, 0.11258164793252945, 0.39602595567703247, 0.31208184361457825, 0.8858895897865295], [0.11220071464776993, 0.03272964060306549, 0.42794322967529297, 0.7649426460266113, 0.5776921510696411, 0.3509371280670166], [0.47899511456489563, 0.5893309116363525, 0.5381185412406921, 0.8290071487426758, 0.5862244963645935, 0.5653369426727295], [0.4503585398197174, 0.7369398474693298, 0.508894681930542, 0.25231632590293884, 0.057925768196582794, 0.9216449856758118], [0.8137121200561523, 0.08781581372022629, 0.42679670453071594, 0.7156791687011719, 0.13306453824043274, 0.7397526502609253], [0.5057214498519897, 0.5732688307762146, 0.17991119623184204, 0.530207633972168, 0.6390567421913147, 0.38212764263153076], [0.7360232472419739, 0.7582994103431702, 0.9093322157859802, 0.15052200853824615, 0.011013302952051163, 0.11714014410972595], [0.005972565617412329, 0.768635094165802, 0.6131902933120728, 0.08844741433858871, 0.8674338459968567, 0.32258152961730957], [0.12240304052829742, 0.8943767547607422, 0.7484471201896667, 0.5326130986213684, 0.21850378811359406, 0.9039451479911804], [0.367098867893219, 0.960311233997345, 0.983381986618042, 0.027631215751171112, 0.3046681582927704, 0.7843057513237], [0.41010457277297974, 0.05021897703409195, 0.008502591401338577, 0.8424225449562073, 0.8950472474098206, 0.20202280580997467], [0.8168241381645203, 0.18534381687641144, 0.5325684547424316, 0.37258490920066833, 0.7557166814804077, 0.7204251885414124], [0.36262184381484985, 0.07695966958999634, 0.32305145263671875, 0.4051797091960907, 0.4741198420524597, 0.4933002293109894], [0.100650854408741, 0.17494896054267883, 0.29443567991256714, 0.48081398010253906, 0.03993529826402664, 0.8912078738212585], [0.47620582580566406, 0.9406110048294067, 0.20011313259601593, 0.9297791719436646, 0.8724716901779175, 0.30327925086021423], [0.6752052903175354, 0.6966137886047363, 0.5786347389221191, 0.4539390504360199, 0.2089507281780243, 0.03193620592355728], [0.09821838140487671, 0.21538008749485016, 0.18395055830478668, 0.9980222582817078, 0.45671072602272034, 0.338046133518219], [0.9263918995857239, 0.6890857219696045, 0.05268515273928642, 0.29376810789108276, 0.31283894181251526, 0.6848043203353882], [0.43440955877304077, 0.9272957444190979, 0.46555328369140625, 0.1887086033821106, 0.9247754216194153, 0.0971662625670433], [0.23957279324531555, 0.7246018648147583, 0.13446000218391418, 0.6042438745498657, 0.4147466719150543, 0.4387356638908386], [0.41943633556365967, 0.9389704465866089, 0.8276585340499878, 0.10731000453233719, 0.8246404528617859, 0.9634082317352295], [0.08887188136577606, 0.9307039380073547, 0.4641014039516449, 0.36182549595832825, 0.5097431540489197, 0.6598897576332092], [0.3623819351196289, 0.7523194551467896, 0.6016247272491455, 0.536295473575592, 0.2919394373893738, 0.31708845496177673], [0.6611452102661133, 0.5863540172576904, 0.6673256158828735, 0.07412562519311905, 0.9646722674369812, 0.21615423262119293], [0.8910329341888428, 0.9905462861061096, 0.03608502820134163, 0.8834338784217834, 0.9098020792007446, 0.731582760810852], [0.5706378817558289, 0.9643404483795166, 0.11696439981460571, 0.44167667627334595, 0.9145136475563049, 0.9091895222663879], [0.5079218149185181, 0.017817482352256775, 0.1096937358379364, 0.34848257899284363, 0.5329350829124451, 0.2091633826494217], [0.5683348178863525, 0.06929361820220947, 0.21107535064220428, 0.8191331028938293, 0.880018949508667, 0.5815348625183105], [0.2033715546131134, 0.8637582063674927, 0.24372738599777222, 0.7988570332527161, 0.3184627294540405, 0.6534998416900635], [0.9408127069473267, 0.12140076607465744, 0.18221375346183777, 0.9948862791061401, 0.45072630047798157, 0.9301372170448303], [0.3572322130203247, 0.6488801836967468, 0.7652938365936279, 0.572934091091156, 0.4479037821292877, 0.04585806652903557], [0.2151358723640442, 0.543793797492981, 0.9543283581733704, 0.4486967623233795, 0.03388988599181175, 0.15615372359752655], [0.1278628557920456, 0.9799365401268005, 0.33942288160324097, 0.38521745800971985, 0.7678391337394714, 0.8544690012931824], [0.23762832581996918, 0.7360753417015076, 0.34121331572532654, 0.869769811630249, 0.1311100721359253, 0.21882447600364685], [0.6391063332557678, 0.8753130435943604, 0.274466872215271, 0.037831101566553116, 0.5357936024665833, 0.15528210997581482], [0.8222588896751404, 0.8006198406219482, 0.3619120717048645, 0.0810275748372078, 0.36563122272491455, 0.2173444926738739], [0.2205738127231598, 0.6783514022827148, 0.10623771697282791, 0.620107889175415, 0.2883111834526062, 0.9235658049583435], [0.96012943983078, 0.8730327486991882, 0.15457136929035187, 0.35209882259368896, 0.16599725186824799, 0.07239343971014023], [0.34051513671875, 0.9826535582542419, 0.2773935794830322, 0.7541703581809998, 0.1444902867078781, 0.7092247009277344], [0.413686066865921, 0.9955867528915405, 0.3560740649700165, 0.1713525503873825, 0.2696063816547394, 0.6472750306129456], [0.1590801179409027, 0.8136470913887024, 0.09083431959152222, 0.13921761512756348, 0.8640458583831787, 0.04207393899559975], [0.5950793623924255, 0.4718746840953827, 0.8057324290275574, 0.5386273860931396, 0.14284300804138184, 0.607350766658783], [0.9175655841827393, 0.5208423137664795, 0.7921020984649658, 0.09858345240354538, 0.3612125515937805, 0.503828227519989], [0.39529949426651, 0.7420775294303894, 0.007153687998652458, 0.11476432532072067, 0.031024938449263573, 0.26716917753219604], [0.7135005593299866, 0.5977815389633179, 0.23341704905033112, 0.32145604491233826, 0.5070266127586365, 0.3307003974914551], [0.05256105959415436, 0.8893986940383911, 0.33282679319381714, 0.02318277396261692, 0.07702634483575821, 0.7807738184928894], [0.7634400129318237, 0.1765822023153305, 0.7966021299362183, 0.834333598613739, 0.30048230290412903, 0.6255083680152893], [0.42921894788742065, 0.10570040345191956, 0.419064462184906, 0.5793030858039856, 0.9551313519477844, 0.37990042567253113], [0.6239505410194397, 0.41115808486938477, 0.19585412740707397, 0.5357530117034912, 0.7161989212036133, 0.3549666404724121], [0.985684335231781, 0.010441005229949951, 0.8344717621803284, 0.33163556456565857, 0.6464312672615051, 0.8928852677345276], [0.04544646665453911, 0.13385245203971863, 0.4577963650226593, 0.6072918772697449, 0.8607218265533447, 0.12040598690509796], [0.9431071281433105, 0.6500372886657715, 0.478971391916275, 0.3746548891067505, 0.48565033078193665, 0.5897572040557861], [0.9715988636016846, 0.7017875909805298, 0.3997175693511963, 0.611204206943512, 0.39829760789871216, 0.13604743778705597], [0.7262816429138184, 0.6898615956306458, 0.24215292930603027, 0.4339964687824249, 0.4821498692035675, 0.44629910588264465], [0.5679954290390015, 0.9680225253105164, 0.580662190914154, 0.1947668194770813, 0.8365640044212341, 0.35836008191108704], [0.5504748225212097, 0.11726061254739761, 0.3955202102661133, 0.3620162010192871, 0.7824642062187195, 0.7209331393241882], [0.19369493424892426, 0.00024507666239514947, 0.9899168610572815, 0.08105514943599701, 0.3800593912601471, 0.7116706967353821], [0.6873116493225098, 0.5470544099807739, 0.562072217464447, 0.8161742687225342, 0.20203150808811188, 0.1012614443898201], [0.21567094326019287, 0.37702053785324097, 0.5005849599838257, 0.9267081022262573, 0.7638972997665405, 0.32606446743011475], [0.937470018863678, 0.817210853099823, 0.8064519762992859, 0.36411282420158386, 0.9948189854621887, 0.4914843738079071], [0.8742597103118896, 0.32531923055648804, 0.23633313179016113, 0.0589284747838974, 0.7963553667068481, 0.695671796798706], [0.30911752581596375, 0.09859726577997208, 0.33751267194747925, 0.36875778436660767, 0.587336540222168, 0.2158784717321396], [0.12228181213140488, 0.7687055468559265, 0.8378515243530273, 0.18776750564575195, 0.10212718695402145, 0.9959906935691833], [0.620779812335968, 0.3170499801635742, 0.2827928066253662, 0.0696839913725853, 0.3664568066596985, 0.14056256413459778], [0.6898185014724731, 0.7438263893127441, 0.7282132506370544, 0.2004564255475998, 0.5102961659431458, 0.5470200777053833], [0.36144569516181946, 0.05611163377761841, 0.10159418731927872, 0.33906090259552, 0.47927334904670715, 0.12001246958971024], [0.7473131418228149, 0.5000090003013611, 0.8980095386505127, 0.6919857263565063, 0.3131489157676697, 0.9095614552497864], [0.8627771735191345, 0.23468568921089172, 0.5547667741775513, 0.6933978199958801, 0.7760478854179382, 0.9618114233016968], [0.2730640172958374, 0.88338702917099, 0.3950076401233673, 0.5013303756713867, 0.27431872487068176, 0.998650848865509], [0.5937970876693726, 0.9023985266685486, 0.1794435977935791, 0.052951544523239136, 0.23872768878936768, 0.22614791989326477], [0.2663322389125824, 0.15457236766815186, 0.05933162197470665, 0.8399713635444641, 0.53246009349823, 0.839403510093689], [0.26763850450515747, 0.4115520119667053, 0.6595265865325928, 0.33939069509506226, 0.7474896311759949, 0.897659182548523], [0.0904780924320221, 0.6731550097465515, 0.46989110112190247, 0.6855628490447998, 0.7670283913612366, 0.6170691847801208], [0.11969422549009323, 0.0032073555048555136, 0.48289695382118225, 0.0392235666513443, 0.18209706246852875, 0.4194408357143402], [0.28633588552474976, 0.03873125836253166, 0.007659840397536755, 0.7280741930007935, 0.4365321099758148, 0.4529692232608795], [0.6367312669754028, 0.17608721554279327, 0.9875624775886536, 0.7431649565696716, 0.26502662897109985, 0.7831200361251831], [0.9254922270774841, 0.6201452612876892, 0.9484957456588745, 0.7531994581222534, 0.14968249201774597, 0.5083160996437073], [0.05771132931113243, 0.09735395759344101, 0.6131229400634766, 0.7489226460456848, 0.5356591939926147, 0.6162995100021362], [0.5726481676101685, 0.41356217861175537, 0.3069327175617218, 0.13108311593532562, 0.8863091468811035, 0.7080078721046448], [0.7094082832336426, 0.1734430491924286, 0.8554773926734924, 0.1836020052433014, 0.3177543580532074, 0.28117918968200684], [0.9533470869064331, 0.5711847543716431, 0.6811321973800659, 0.6927375793457031, 0.787315309047699, 0.35073602199554443], [0.17006514966487885, 0.3519476652145386, 0.41775819659233093, 0.9454044699668884, 0.3294971287250519, 0.4223079979419708], [0.5852910280227661, 0.3532857894897461, 0.6364582777023315, 0.2490067034959793, 0.5438897609710693, 0.43385231494903564]]
    # predict("model_my.pt", test_vec)